# Attention is all you need (Keras) [WIP]
Implementation of the Transformer architecture described by Vaswani et al. in "Attention Is All You Need" using the [Keras Utility & Layer Collection (kulc)](https://github.com/FlashTek/keras-layer-collection).
